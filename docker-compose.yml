services:
  caddy:
    image: caddy:2.7
    restart: unless-stopped
    ports:
      - 127.0.0.1:3000:80
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - caddy
    environment:
      - FQDN=$FQDN
      - OPENAI_API_KEY=$OPENAI_API_KEY

  litellm:
    image: ghcr.io/berriai/litellm:main-v1.35.8
    restart: unless-stopped
    volumes:
      - ./litellm_config.yaml:/app/litellm_config.yaml
      - $GOOGLE_CREDENTIAL_PATH:/app/google_credentials.json
    networks:
      - caddy
      - postgres
      - ollama
    ports:
      - 127.0.0.1:4000:4000
    command: [ "--config", "/app/litellm_config.yaml", "--port", "4000", "--num_workers", "4" ]
    environment:
      - ANTHROPIC_API_KEY=$ANTHROPIC_API_KEY
      - GOOGLE_APPLICATION_CREDENTIALS=/app/google_credentials.json
      - GOOGLE_VERTEX_PROJECT=$GOOGLE_VERTEX_PROJECT
      - GOOGLE_VERTEX_LOCATION=$GOOGLE_VERTEX_LOCATION
      - OPENAI_API_KEY=$OPENAI_API_KEY
      - POSTGRES_DB_URL=$POSTGRES_DB_URL
      - UI_PASSWORD=$UI_PASSWORD
      - UI_USERNAME=$UI_USERNAME

  postgres:
    image: postgres
    restart: unless-stopped
    shm_size: 128mb
    volumes:
      - postgres_db:/var/lib/postgresql/data
    networks:
      - postgres
    environment:
      - POSTGRES_USER=$POSTGRES_USER
      - POSTGRES_PASSWORD=$POSTGRES_PASSWORD

  ollama:
    image: ollama/ollama:0.1.32
    restart: unless-stopped
    volumes:
      - ollama:/root/.ollama
      - ./models:/models
    ports:
      - 127.0.0.1:11434:11434
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
    networks:
      - ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-webui-local:
    image: ollama-webui:local
    restart: unless-stopped
    init: true
    ports:
      - 127.0.0.1:3001:8080
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434/api
    networks:
      - caddy
      - ollama

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    restart: unless-stopped
    init: true
    volumes:
      - ollama-webui:/app/backend/data
    ports:
      - 127.0.0.1:3002:8080
    networks:
      - caddy
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434/api
      - OPENAI_API_BASE_URL=http://litellm:4000/

  nextchat:
    image: nextchat:custom
    restart: unless-stopped
    ports:
      - 127.0.0.1:3003:3000
    networks:
      - caddy
    environment:
      - OPENAI_API_KEY=any
      - BASE_URL=http://litellm:4000/
      - HIDE_USER_API_KEY=1
      - CUSTOM_MODELS=-all,openai-gpt-3.5-turbo,openai-gpt-4-turbo,google-gemini-1.5-pro,anthropic-claude-3-sonnet,anthropic-claude-3-opus

  yakgpt:
    image: yakgpt/yakgpt:latest
    restart: unless-stopped
    ports:
      - 127.0.0.1:3004:3000
    networks:
      - caddy

networks:
  caddy:
  postgres:
  ollama:

volumes:
  caddy_config:
  caddy_data:
  postgres_db:
  ollama-webui:
  ollama:
